{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oVVIwQSVIXFTagDvpIdhCf0u2_rluVdX",
      "authorship_tag": "ABX9TyMELm/RaSx3jRg98VgNBmDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorningStarTM/Transformers-in-Vision/blob/main/ViT_for_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7YtNmAUNkDmN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "8eb9d75d-d10d-451f-f6e9-b4896c2524ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-fdad11cb8761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpatchify\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpatchify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from patchify import patchify\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.model import Model\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter\n",
        "hp = {}\n",
        "hp['image_size'] = 200\n",
        "hp['num_channel'] = 3\n",
        "hp['patch_size'] = 25\n",
        "hp['num_patches'] = (hp['image_size']**2) // (hp['patch_size']**2)\n",
        "hp['flat_patches_shape'] = (hp['num_patches'], hp['patch_size']*hp['patch_size']*hp['num_channel'])\n",
        "\n",
        "hp['batch_size'] = 32\n",
        "hp['lr'] = 1e-4\n",
        "hp['num_epochs'] = 500\n",
        "hp['num_classes'] = 9\n",
        "hp['class_names'] = [\"Ant\", \"Butterfly\", \"Cockroach\", \"Frog\", \"Grasshopper\", \"Honey bee\", \"Spider\", \"dragonfly\", \"lizard\"]"
      ],
      "metadata": {
        "id": "IIwt-ayzjr-Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/archive podiwije.zip\" -d \"/content/drive/MyDrive/DataSet/Insects/\""
      ],
      "metadata": {
        "id": "AEAqzic4lV_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/DataSet/Insects/Reptiles-Insects\""
      ],
      "metadata": {
        "id": "VI6YB9_PV1iy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(path):\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ],
      "metadata": {
        "id": "kQoCu05Sngs3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for load the data file\n",
        "def load_data(path, split=0.1):\n",
        "  images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
        "  \n",
        "  split_size = int(len(images) * split)\n",
        "  #split the data \n",
        "  train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "  train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "\n",
        "  return train_x, valid_x, test_x"
      ],
      "metadata": {
        "id": "wb7uK2h2mowR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image_label(path):\n",
        "  path = path.decode()\n",
        "  #read image\n",
        "  image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "  #resize the image\n",
        "  image = cv2.resize(image, (hp['image_size'], hp['image_size']))\n",
        "  #scale the image\n",
        "  image = image/255.0\n",
        "  print(image.shape)\n",
        "\n",
        "  #image into patch\n",
        "  patch_shape = (hp['patch_size'], hp['patch_size'], hp['num_channel'])\n",
        "  patches = patchify(image, patch_shape, hp['patch_size'])\n",
        "\n",
        "  patches = np.reshape(patches, hp['flat_patches_shape'])\n",
        "  patches = patches.astype(np.float32)\n",
        "  print(path)\n",
        "\n",
        "  #labeling\n",
        "  class_name = path.split('/')[-2]\n",
        "  class_idx = hp['class_names'].index(class_name)\n",
        "  class_idx = np.array(class_idx, dtype=np.int32)\n",
        "  print(class_idx)\n",
        "\n",
        "  return patches, class_idx"
      ],
      "metadata": {
        "id": "uhj0VIWomvsf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we used opencv to read images not tensorflow. so we need to use tf.numpy_function to use these function in tensorflow\n",
        "def parse(path):\n",
        "  patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
        "  labels = tf.one_hot(labels, hp['num_classes'])\n",
        "\n",
        "  patches.set_shape(hp['flat_patches_shape'])\n",
        "  labels.set_shape(hp['num_classes'])\n",
        "\n",
        "  return patches, labels"
      ],
      "metadata": {
        "id": "5XmF8f5Ys6CW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_dataset(images, batch=32):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((images))\n",
        "  dataset = dataset.map(parse).batch(batch).prefetch(8)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "9L78Lr-h5UId"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, valid_x, test_x = load_data(dataset_path)"
      ],
      "metadata": {
        "id": "wuaUgiODmgXA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train: {len(train_x)} Valid: {len(valid_x)} Test: {len(test_x)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVWcWGUkv-1O",
        "outputId": "f9911eaa-91eb-481b-b289-d1836f9b24b5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 680 Valid: 85 Test: 85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf_dataset(train_x, batch=hp['batch_size'])\n",
        "valid_dataset = tf_dataset(valid_x, batch=hp['batch_size'])"
      ],
      "metadata": {
        "id": "FtMATx_X0cy-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "JomcQiMIC6GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuratin parameters\n",
        "config = {}\n",
        "config['num_layers'] = 12\n",
        "config['hidden_dim'] = 768\n",
        "config['mlp_dim'] = 3072\n",
        "config['num_heads'] = 12\n",
        "config['dropout_rate'] = 0.1\n",
        "config['num_patches'] = 256\n",
        "config['patch_size'] = 32\n",
        "config['num_channels'] = 3"
      ],
      "metadata": {
        "id": "fGL9R5Vt7OAa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ViT(config):\n",
        "  #input layer\n",
        "  input_shape = (config['num_patches'], config['patch_size']*config['patch_size']*config['num_channels'])\n",
        "  inputs = Input(input_shape)\n",
        "  \n",
        "  #patch and position embedding\n",
        "  patch_embedding = Dense(config['hidden_dim'])(inputs)\n",
        "  \n",
        "  positions = tf.range(start=0, limit=config['num_patches'], delta=1)\n",
        "  position_embedding = Embedding(input_dim=config['num_patches'], output_dim=config['hidden_dim'])(positions)\n",
        "  print(position_embedding.shape)"
      ],
      "metadata": {
        "id": "NoEtYhQIEtsh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ViT(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdZBmBtcGjXz",
        "outputId": "289311fd-e611-4a5a-f6ed-196af5f501de"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZBeJD74fG0xN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}