{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from glob import glob\n",
    "from patchify import patchify\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(data_path):\n",
    "    names = os.listdir(data_path)\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\ML_test\\\\Data\\\\bird-groups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = get_class_name(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "hp = {}\n",
    "hp['image_size'] = 200\n",
    "hp['num_channel'] = 3\n",
    "hp['patch_size'] = 25\n",
    "hp['num_patches'] = (hp['image_size']**2) // (hp['patch_size']**2)\n",
    "hp['flat_patches_shape'] = (hp['num_patches'], hp['patch_size']*hp['patch_size']*hp['num_channel'])\n",
    "\n",
    "hp['batch_size'] = 16\n",
    "hp['lr'] = 1e-4\n",
    "hp['num_epochs'] = 100 \n",
    "hp['num_classes'] = 9\n",
    "hp['class_names'] = names\n",
    "\n",
    "hp[\"num_layers\"] = 12\n",
    "hp[\"hidden_dim\"] = 500 \n",
    "hp[\"mlp_dim\"] = 3072\n",
    "hp[\"num_heads\"] = 12\n",
    "hp[\"dropout_rate\"] = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for load dataset\n",
    "def load_data(path, split=0.1):\n",
    "    images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
    "    \n",
    "    split_size = int(len(images) * split)\n",
    "    #split the data\n",
    "    train_data, valid_data = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_data, test_data = train_test_split(train_data, test_size=split_size, random_state=42)\n",
    "\n",
    "    return train_data, valid_data, test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2238 - Valid: 279 - Test: 279\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data  = load_data(path)\n",
    "print(f\"Train: {len(train_data)} - Valid: {len(valid_data)} - Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path):\n",
    "    #decode the path\n",
    "    path = path.decode()\n",
    "    #read image\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    #resize the image\n",
    "    image = cv2.resize(image, (hp['image_size'], hp['image_size']))\n",
    "    #scale the image\n",
    "    image = image / 255.0\n",
    "\n",
    "    #convert image into patch\n",
    "    patch_shape = (hp['patch_size'], hp['patch_size'], hp['num_channel'])\n",
    "    patches = patchify(image, patch_shape, hp['patch_size'])\n",
    "\n",
    "    #labeling the image\n",
    "    class_name = path.split(\"\\\\\")[-2]\n",
    "    class_idx = hp['class_names'].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "\n",
    "    return patches, class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image, [path], (tf.float32, tf.int32))\n",
    "    labels = tf.one_hot(labels, hp['num_classes'])\n",
    "\n",
    "    patches.set_shape(hp['flat_patches_shape'])\n",
    "    labels.set_shape(hp['num_classes'])\n",
    "\n",
    "    return patches, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow dataset\n",
    "def tf_dataset(images, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images))\n",
    "    dataset = dataset.map(parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(8)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(train_data, batch=hp['batch_size'])\n",
    "valid_dataset = tf_dataset(valid_data, batch=hp['batch_size'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuratin parameters\n",
    "config = {}\n",
    "config['num_layers'] = 12\n",
    "config['hidden_dim'] = 768\n",
    "config['mlp_dim'] = 3072\n",
    "config['num_heads'] = 12\n",
    "config['dropout_rate'] = 0.1\n",
    "config['num_patches'] = 256\n",
    "config['patch_size'] = 32\n",
    "config['num_channels'] = 3\n",
    "config[\"num_classes\"] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(input, config):\n",
    "    inputs = Dense(config['mlp_dim'], activation='gelu')(inputs)\n",
    "    inputs = Dropout(config['dropout_rate'])(inputs)\n",
    "    inputs = Dense(config['hidden_dim'])(inputs)\n",
    "    inputs = Dropout(config['dropout_rate'])(inputs)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, config):\n",
    "    skip_connection_1 = inputs\n",
    "    inputs = LayerNormalization()(inputs)\n",
    "    inputs = MultiHeadAttention(\n",
    "        num_head=config['num_heads'],\n",
    "        key_dim=config['hidden_dim']\n",
    "    )(inputs, inputs)\n",
    "    inputs = Add()([inputs, skip_connection_1])\n",
    "\n",
    "    skip_connection_2 = inputs\n",
    "    inputs = LayerNormalization()(inputs)\n",
    "    inputs = mlp(inputs, config)\n",
    "    inputs = Add()([inputs, skip_connection_2])\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b778f98153833a34c3ea8ba51064b6a8427692c2a3735102839451caad10934"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
